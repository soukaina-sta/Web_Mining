{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (3.5.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (63.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  'The food we had yesterday was delicious',\n",
    "  'My time in Italy was very enjoyable',\n",
    "  'I found the meal to be tasty',\n",
    "  'The internet was slow.',\n",
    "  'Our experience was suboptimal'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to split our sentences in such a way as to obtain the aspect (ex: food) and its expression (ex: delicious)\n",
    "\n",
    "For each token inside our sentences, we can see the dependency through spacy's dependency analysis and POS (Part-Of-Speech)tags\n",
    "https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det food NOUN DET []\n",
      "food nsubj was AUX NOUN [The, had]\n",
      "we nsubj had VERB PRON []\n",
      "had relcl food NOUN VERB [we, yesterday]\n",
      "yesterday npadvmod had VERB NOUN []\n",
      "was ROOT was AUX AUX [food, delicious]\n",
      "delicious acomp was AUX ADJ []\n",
      "My poss time NOUN PRON []\n",
      "time nsubj was AUX NOUN [My, in]\n",
      "in prep time NOUN ADP [Italy]\n",
      "Italy pobj in ADP PROPN []\n",
      "was ROOT was AUX AUX [time, enjoyable]\n",
      "very advmod enjoyable ADJ ADV []\n",
      "enjoyable acomp was AUX ADJ [very]\n",
      "I nsubj found VERB PRON []\n",
      "found ROOT found VERB VERB [I, be]\n",
      "the det meal NOUN DET []\n",
      "meal nsubj be AUX NOUN [the]\n",
      "to aux be AUX PART []\n",
      "be ccomp found VERB AUX [meal, to, tasty]\n",
      "tasty acomp be AUX ADJ []\n",
      "The det internet NOUN DET []\n",
      "internet nsubj was AUX NOUN [The]\n",
      "was ROOT was AUX AUX [internet, slow, .]\n",
      "slow acomp was AUX ADJ []\n",
      ". punct was AUX PUNCT []\n",
      "Our poss experience NOUN PRON []\n",
      "experience nsubj was AUX NOUN [Our]\n",
      "was ROOT was AUX AUX [experience, suboptimal]\n",
      "suboptimal acomp was AUX ADJ []\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(token.text, token.dep_, token.head.text, token.head.pos_,token.pos_,[child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of dependency visualization in a sentence:\n",
    "\n",
    "https://spacy.io/usage/visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\spacy\\displacy\\__init__.py:108: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The food we had \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yesterday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " was delicious</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "doc = nlp(\"The food we had yesterday was delicious\")\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the linguistic characteristics and in particular the POS, we will extract the adjectives as expression of sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delicious\n",
      "enjoyable\n",
      "tasty\n",
      "slow\n",
      "suboptimal\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    descriptive_term = ''\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'ADJ':\n",
    "            descriptive_term = token\n",
    "    #print(sentence)\n",
    "    print(descriptive_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, what's missing are intensifiers like \"very\" (we'll avoid adverbs). we will extract them using the children property.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food we had yesterday was delicious\n",
      "delicious\n",
      "My time in Italy was very enjoyable\n",
      "very enjoyable\n",
      "I found the meal to be tasty\n",
      "tasty\n",
      "The internet was slow.\n",
      "slow\n",
      "Our experience was suboptimal\n",
      "suboptimal\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    descriptive_term = ''\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'ADJ':\n",
    "            prepend = ''\n",
    "            for child in token.children:\n",
    "                if child.pos_ != 'ADV':\n",
    "                    continue\n",
    "                prepend += child.text + ' '\n",
    "            descriptive_term = prepend + token.text\n",
    "    print(sentence)\n",
    "    print(descriptive_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put that in a dictionary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious'}, {'aspect': 'time', 'description': 'very enjoyable'}, {'aspect': 'meal', 'description': 'tasty'}, {'aspect': 'internet', 'description': 'slow'}, {'aspect': 'experience', 'description': 'suboptimal'}]\n"
     ]
    }
   ],
   "source": [
    "aspects = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    descriptive_term = ''\n",
    "    target = ''\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.pos_ == 'NOUN':\n",
    "            target = token.text\n",
    "        if token.pos_ == 'ADJ':\n",
    "            prepend = ''\n",
    "            for child in token.children:\n",
    "                if child.pos_ != 'ADV':\n",
    "                    continue\n",
    "                prepend += child.text + ' '\n",
    "            descriptive_term = prepend + token.text\n",
    "\n",
    "    aspects.append({'aspect': target, 'description': descriptive_term})\n",
    "\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using TextBlob for sentiment extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting TextBlob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     -------------------------------------- 636.8/636.8 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from TextBlob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from nltk>=3.1->TextBlob) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk>=3.1->TextBlob) (0.4.6)\n",
      "Installing collected packages: TextBlob\n",
      "Successfully installed TextBlob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a library that offers out-of-the-box sentiment analysis. It has a bag of words approach, which means it has a list of words such as “good”, “bad” and “excellent” that have a sentiment score attached to them. It is also able to select modifiers (such as “not”) and intensifiers (such as “very”) that affect the sentiment score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': Sentiment(polarity=1.0, subjectivity=1.0)}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': Sentiment(polarity=0.65, subjectivity=0.78)}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}, {'aspect': 'internet', 'description': 'slow', 'sentiment': Sentiment(polarity=-0.30000000000000004, subjectivity=0.39999999999999997)}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': Sentiment(polarity=0.0, subjectivity=0.0)}]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "for aspect in aspects:\n",
    "    aspect['sentiment'] = TextBlob(aspect['description']).sentiment\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at the results we can notice that the adjectives \"tasty\" and \"suboptimal\" are considered neutral. It looks like they are not part of TextBlob's dictionary and therefore not picked up.\n",
    "\n",
    "TextBlob allows us to train a NaiveBayesClassifier using a very simple and easy-to-understand syntax for everyone, which we will use to improve our sentiment analysis. \n",
    "\n",
    "Thus, we will perform a Corpus-Based Sentiment Lexicon Acquisition using TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delicious food.\n",
      "positive\n",
      "Very Slow internet.\n",
      "negative\n",
      "Suboptimal experience\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "# We train the NaivesBayesClassifier\n",
    "train = [\n",
    "  ('Slow internet', 'negative'),\n",
    "  ('Delicious food', 'positive'),\n",
    "  ('Suboptimal experience', 'negative'),\n",
    "  (' enjoyable time', 'positive'),\n",
    "  ('delicious food.', 'negative')\n",
    "]\n",
    "cl = NaiveBayesClassifier(train)# And then we try to classify some sample sentences.\n",
    "blob = TextBlob(\"Delicious food. Very Slow internet. Suboptimal experience\", classifier=cl)\n",
    "for s in blob.sentences:\n",
    "    print(s)\n",
    "    print(s.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now redo our classification using the trainer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'aspect': 'food', 'description': 'delicious', 'sentiment': 'negative'}, {'aspect': 'time', 'description': 'very enjoyable', 'sentiment': 'positive'}, {'aspect': 'meal', 'description': 'tasty', 'sentiment': 'negative'}, {'aspect': 'internet', 'description': 'slow', 'sentiment': 'negative'}, {'aspect': 'experience', 'description': 'suboptimal', 'sentiment': 'negative'}]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "for aspect in aspects:\n",
    "    blob = TextBlob(aspect['description'], classifier=cl)  \n",
    "    aspect['sentiment'] = blob.classify()\n",
    "print(aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To DO:\n",
    "\n",
    "1. Try on other sentences using the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I feel amazing!': positive\n",
      " I hate Mondays.\n",
      "Sentiment: negative\n",
      "\n",
      " But I love weekends.\n",
      "Sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier,DecisionTreeClassifier\n",
    "\n",
    "train = [\n",
    "    ('I love the weather.', 'positive'),\n",
    "    ('it was an amazing show', 'positive'),\n",
    "    ('I feel very good today.', 'positive'),\n",
    "    ('I do not agree', 'negative'),\n",
    "    ('I am tired of this stuff.', 'negative'),\n",
    "    (\"I can't deal with this\", 'negative'),\n",
    "    (\"My boss is horrible.\", \"negative\")\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "sentiment = cl.classify(\"I feel amazing!\")\n",
    "print(f\"'I feel amazing!': {sentiment}\")\n",
    "\n",
    "blob = TextBlob(\"I hate Mondays. But I love weekends.\", classifier=cl)\n",
    "for sentence in blob.sentences:\n",
    "    print(f\" {sentence}\")\n",
    "    print(f\"Sentiment: {sentence.classify()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weekend was good .\n",
      "positive\n",
      "But the monday is horrible.\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import DecisionTreeClassifier\n",
    "\n",
    "# Ensemble d'entraînement\n",
    "train = [\n",
    "    ('I love this movie.', 'positive'),\n",
    "    ('The food was delicious.', 'positive'),\n",
    "    ('The weather is beautiful today.', 'positive'),\n",
    "    ('I hate Mondays.', 'negative'),\n",
    "    ('This book is boring.', 'negative'),\n",
    "    ('I feel sick.', 'negative')\n",
    "]\n",
    "\n",
    "# Entraînement du classificateur\n",
    "cl = DecisionTreeClassifier(train)\n",
    "blob = TextBlob(\"The weekend was good . But the monday is horrible.\", classifier=cl)\n",
    "for s in blob.sentences:\n",
    "    print(s)\n",
    "    print(s.classify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytest = [\n",
    "    ('The movie was amazing!', 'positive'),\n",
    "    ('I cannot stand the rain.', 'negative'),\n",
    "    ('The meal was disappointing.', 'negative'),\n",
    "    ('I enjoy outdoor activities.', 'positive')\n",
    "]\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (1.23.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\pc\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  MaxEntClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons  une sortie indiquant les résultats de l'entraînement du classifieur.\n",
    "\n",
    "À chaque itération, le \"Log Likelihood\" diminue, ce qui indique que le modèle s'améliore dans la prédiction des étiquettes. L'\"Accuracy\" est de 1.000 à chaque itération, ce qui signifie que le modèle prévoit correctement toutes les étiquettes de l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weekend was good.\n",
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.500\n",
      "             2          -0.59581        1.000\n",
      "             3          -0.52044        1.000\n",
      "             4          -0.46061        1.000\n",
      "             5          -0.41223        1.000\n",
      "             6          -0.37244        1.000\n",
      "             7          -0.33923        1.000\n",
      "             8          -0.31113        1.000\n",
      "             9          -0.28710        1.000\n",
      "            10          -0.26632        1.000\n",
      "            11          -0.24820        1.000\n",
      "            12          -0.23228        1.000\n",
      "            13          -0.21818        1.000\n",
      "            14          -0.20561        1.000\n",
      "            15          -0.19436        1.000\n",
      "            16          -0.18422        1.000\n",
      "            17          -0.17504        1.000\n",
      "            18          -0.16670        1.000\n",
      "            19          -0.15908        1.000\n",
      "            20          -0.15211        1.000\n",
      "            21          -0.14570        1.000\n",
      "            22          -0.13978        1.000\n",
      "            23          -0.13432        1.000\n",
      "            24          -0.12925        1.000\n",
      "            25          -0.12454        1.000\n",
      "            26          -0.12014        1.000\n",
      "            27          -0.11604        1.000\n",
      "            28          -0.11220        1.000\n",
      "            29          -0.10860        1.000\n",
      "            30          -0.10522        1.000\n",
      "            31          -0.10203        1.000\n",
      "            32          -0.09903        1.000\n",
      "            33          -0.09619        1.000\n",
      "            34          -0.09351        1.000\n",
      "            35          -0.09097        1.000\n",
      "            36          -0.08856        1.000\n",
      "            37          -0.08628        1.000\n",
      "            38          -0.08410        1.000\n",
      "            39          -0.08203        1.000\n",
      "            40          -0.08006        1.000\n",
      "            41          -0.07817        1.000\n",
      "            42          -0.07637        1.000\n",
      "            43          -0.07466        1.000\n",
      "            44          -0.07301        1.000\n",
      "            45          -0.07143        1.000\n",
      "            46          -0.06992        1.000\n",
      "            47          -0.06848        1.000\n",
      "            48          -0.06708        1.000\n",
      "            49          -0.06575        1.000\n",
      "            50          -0.06446        1.000\n",
      "            51          -0.06322        1.000\n",
      "            52          -0.06203        1.000\n",
      "            53          -0.06088        1.000\n",
      "            54          -0.05978        1.000\n",
      "            55          -0.05871        1.000\n",
      "            56          -0.05768        1.000\n",
      "            57          -0.05668        1.000\n",
      "            58          -0.05572        1.000\n",
      "            59          -0.05479        1.000\n",
      "            60          -0.05389        1.000\n",
      "            61          -0.05301        1.000\n",
      "            62          -0.05217        1.000\n",
      "            63          -0.05135        1.000\n",
      "            64          -0.05055        1.000\n",
      "            65          -0.04978        1.000\n",
      "            66          -0.04904        1.000\n",
      "            67          -0.04831        1.000\n",
      "            68          -0.04761        1.000\n",
      "            69          -0.04692        1.000\n",
      "            70          -0.04626        1.000\n",
      "            71          -0.04561        1.000\n",
      "            72          -0.04498        1.000\n",
      "            73          -0.04437        1.000\n",
      "            74          -0.04377        1.000\n",
      "            75          -0.04319        1.000\n",
      "            76          -0.04262        1.000\n",
      "            77          -0.04207        1.000\n",
      "            78          -0.04153        1.000\n",
      "            79          -0.04101        1.000\n",
      "            80          -0.04050        1.000\n",
      "            81          -0.04000        1.000\n",
      "            82          -0.03951        1.000\n",
      "            83          -0.03904        1.000\n",
      "            84          -0.03858        1.000\n",
      "            85          -0.03812        1.000\n",
      "            86          -0.03768        1.000\n",
      "            87          -0.03725        1.000\n",
      "            88          -0.03682        1.000\n",
      "            89          -0.03641        1.000\n",
      "            90          -0.03601        1.000\n",
      "            91          -0.03561        1.000\n",
      "            92          -0.03522        1.000\n",
      "            93          -0.03484        1.000\n",
      "            94          -0.03447        1.000\n",
      "            95          -0.03411        1.000\n",
      "            96          -0.03375        1.000\n",
      "            97          -0.03340        1.000\n",
      "            98          -0.03306        1.000\n",
      "            99          -0.03273        1.000\n",
      "         Final          -0.03240        1.000\n",
      "positive\n",
      "But the Monday is horrible.\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import MaxEntClassifier\n",
    "\n",
    "train = [\n",
    "    ('I love this movie.', 'positive'),\n",
    "    ('The food was delicious.', 'positive'),\n",
    "    ('The weather is beautiful today.', 'positive'),\n",
    "    ('I hate Mondays.', 'negative'),\n",
    "    ('This book is boring.', 'negative'),\n",
    "    ('I feel sick.', 'negative')\n",
    "]\n",
    "\n",
    "cl = MaxEntClassifier(train)\n",
    "\n",
    "blob = TextBlob(\"The weekend was good. But the Monday is horrible.\", classifier=cl)\n",
    "for s in blob.sentences:\n",
    "    print(s)\n",
    "    print(s.classify())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
